"""
Description:
    This script defines a PyTorch ResNet-based embedding model (using SimCLR-style contrastive learning) 
    for extracting feature vectors from rasterized building footprint images.

Features:
    - Loads binary building images from a .npz file (generated by the rasterization script).
    - Defines a dataset class for efficient image loading and augmentation.
    - Implements a ResNet18 backbone with a projection head for feature embedding.
    - Supports training with SimCLR-style contrastive loss (InfoNCE).
    - Provides functions to extract and save building embeddings for downstream tasks.

Note:
    This script assumes you have already run the rasterization pipeline to generate the rasterized building images.
"""

import os
import random
import numpy as np
import torch
import torch.nn.functional as F
from torch import nn
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import zipfile

#------------- Dataset for loading building images from an npz file.----------

class ImageDataset(Dataset):
    def __init__(self, npz_file, extract_path="temp_building_images"):
        super().__init__()
        # Extract the npz file if needed (portable way)
        if not os.path.exists(extract_path):
            os.makedirs(extract_path)
        with zipfile.ZipFile(npz_file, 'r') as zf:
            npy_name = zf.namelist()[0]
            zf.extract(npy_name, path=extract_path)
        npy_file = os.path.join(extract_path, npy_name)
        self.images = np.load(npy_file, mmap_mode="r")
        print('Loaded image data:', self.images.shape)

    def __getitem__(self, index):
        return self.images[index]

    def __len__(self):
        return self.images.shape[0]

    def collate_fn_augmentation(batch):
        result = []
        augmentations = [lambda x: x,
                         lambda x: np.flip(x, axis=0),
                         lambda x: np.flip(x, axis=1),
                         lambda x: np.rot90(x, k=1, axes=(0, 1)),
                         lambda x: np.rot90(x, k=2, axes=(0, 1)),
                         lambda x: np.rot90(x, k=3, axes=(0, 1))]
        for pic in batch:
            choice1 = random.choice(augmentations)
            choice2 = random.choice(augmentations)
            result.append(choice1(pic)[np.newaxis, :, :])
            result.append(choice2(pic)[np.newaxis, :, :])
        return np.concatenate(result, axis=0)

    def collate_fn_embed(batch):
        return np.vstack([pic[np.newaxis, :, :] for pic in batch])

class ResNetEmbedder(nn.Module):
    def __init__(self):
        super().__init__()
        import timm
        net = timm.create_model('resnet18', pretrained=True)
        self.net = nn.Sequential(*(list(net.children())[:-1]))
        self.projector = nn.Sequential(
            nn.Linear(512, 1024), nn.ReLU(),
            nn.Linear(1024, 1024), nn.ReLU(),
            nn.Linear(1024, 64))  # 64-dim embedding

    def forward(self, x):
        return self.projector(self.get_feature(x))

    def get_feature(self, x):
        x = x.unsqueeze(1).repeat(1, 3, 1, 1)  # 1ch â†’ 3ch
        x = self.net(x)
        return x.view(x.shape[0], -1)

class SimCLRTrainer:
    def __init__(self, npz_file, device="cuda"):
        self.data = ImageDataset(npz_file)
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = ResNetEmbedder().to(self.device)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.0001)
        self.criterion = self.infonce_loss
        self.train_loader = DataLoader(
            self.data, batch_size=128, shuffle=True, collate_fn=ImageDataset.collate_fn_augmentation)
        self.test_loader = DataLoader(
            self.data, batch_size=128, shuffle=False, collate_fn=ImageDataset.collate_fn_embed)

    def train(self, epochs):
        self.model.train()
        for epoch in range(epochs):
            losses = []
            for x in tqdm(self.train_loader, total=len(self.train_loader), desc=f"Epoch {epoch}"):
                x = torch.from_numpy(x).float().to(self.device)
                self.optimizer.zero_grad()
                y_pred = self.model(x)
                loss = self.criterion(y_pred)
                loss.backward()
                self.optimizer.step()
                losses.append(loss.item())
            print(f"Epoch {epoch} mean loss: {np.mean(losses)}")

    def embed(self):
        self.model.eval()
        embeddings = []
        with torch.no_grad():
            for x in self.test_loader:
                x = torch.from_numpy(x).float().to(self.device)
                embeddings.append(self.model(x).cpu().numpy())
        return np.concatenate(embeddings, axis=0)

    def infonce_loss(self, y_pred, lamda=0.05):
        idxs = torch.arange(0, y_pred.shape[0], device=self.device)
        y_true = idxs + 1 - idxs % 2 * 2
        similarities = F.cosine_similarity(y_pred.unsqueeze(1), y_pred.unsqueeze(0), dim=2)
        similarities = similarities - torch.eye(y_pred.shape[0], device=self.device) * 1e12
        similarities = similarities / lamda
        loss = F.cross_entropy(similarities, y_true)
        return torch.mean(loss)

if __name__ == '__main__':
    npz_file = "output/building_raster.npz"     
    trainer = SimCLRTrainer(npz_file)
    trainer.train(epochs=3)    
    embeddings = trainer.embed()
    np.save("output/building_features.npy", embeddings)
    print("Saved embeddings shape:", embeddings.shape)
